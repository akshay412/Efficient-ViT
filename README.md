# Efficient-ViT
Optimizing Vision Transformers (ViTs) for resource-constrained environments by reducing model size and inference latency while maintaining performance. Implements flash attention, attention head pruning, teacher-student distillation, and quantization, inspired by the Once-for-All approach for CNNs.
