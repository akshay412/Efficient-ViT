{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pQpgIbE5J6uR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, AutoFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch.profiler import profile, record_function, ProfilerActivity, schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ulldiV6WJ9Bx"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters for training\n",
    "learning_rate = 0.0002\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 8\n",
    "num_epochs = 4\n",
    "seed = 42\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Transform for CIFAR100 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYUoPJFCKN6w",
    "outputId": "06359494-8c87-48a9-bbac-56ba021a1f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTSdpaAttention(\n",
       "            (attention): ViTSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset and make ddata loader\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=train_batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(testset, batch_size=eval_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Load pre-trained ViT model\n",
    "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=100)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DgFthfPwKS8X"
   },
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvAIns_DJ5X7",
    "outputId": "1414ea19-1ac5-40b4-f742-5875bed697fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 3125/3125 [29:53<00:00,  1.74it/s]\n",
      "Evaluating: 100%|██████████| 1250/1250 [01:58<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "Train Loss: 1.1488, Train Accuracy: 0.7275\n",
      "Eval Loss: 0.7587, Eval Accuracy: 0.7886\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4: 100%|██████████| 3125/3125 [29:54<00:00,  1.74it/s]\n",
      "Evaluating: 100%|██████████| 1250/1250 [01:59<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\n",
      "Train Loss: 0.5075, Train Accuracy: 0.8518\n",
      "Eval Loss: 0.6755, Eval Accuracy: 0.8113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4: 100%|██████████| 3125/3125 [30:04<00:00,  1.73it/s]\n",
      "Evaluating: 100%|██████████| 1250/1250 [01:59<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4\n",
      "Train Loss: 0.3714, Train Accuracy: 0.8891\n",
      "Eval Loss: 0.6988, Eval Accuracy: 0.8056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4: 100%|██████████| 3125/3125 [30:01<00:00,  1.73it/s]\n",
      "Evaluating: 100%|██████████| 1250/1250 [01:59<00:00, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4\n",
      "Train Loss: 0.2958, Train Accuracy: 0.9101\n",
      "Eval Loss: 0.8210, Eval Accuracy: 0.7794\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    eval_correct = 0\n",
    "    eval_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            eval_total += labels.size(0)\n",
    "            eval_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    eval_loss /= len(test_loader)\n",
    "    eval_accuracy = eval_correct / eval_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Eval Loss: {eval_loss:.4f}, Eval Accuracy: {eval_accuracy:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9A_1pfWKYU5"
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "torch.save(model.state_dict(), \"vit_cifar100_finetuned.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yx16XQJa-3b9",
    "outputId": "bfbfe597-3201-44b3-fccf-e9c0d2207913"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict = torch.load('vit_cifar100_finetuned.pth', weights_only=True)\n",
    "state_dict = torch.load('vit_cifar100_finetuned.pth', weights_only=True, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the state dict into your model\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIljev34DyCU"
   },
   "outputs": [],
   "source": [
    "# Define evalutation function with latency and accuracy\n",
    "\n",
    "def eval_op(model, prof):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    eval_correct_top1 = 0\n",
    "    eval_correct_top3 = 0\n",
    "    eval_total = 0\n",
    "\n",
    "    # Start timing\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            # Get the top 1 and top 3 predictions\n",
    "            _, top1_predicted = outputs.max(1)\n",
    "            _, top3_predicted = outputs.topk(3, 1, largest=True, sorted=True)\n",
    "\n",
    "            # Calculate top-1 accuracy\n",
    "            eval_correct_top1 += top1_predicted.eq(labels).sum().item()\n",
    "\n",
    "            # Expand labels to match the shape of top3_predicted\n",
    "            labels_expanded = labels.view(-1, 1).expand_as(top3_predicted)\n",
    "\n",
    "            # Check if the correct label is in the top 3 predictions\n",
    "            correct_top3 = top3_predicted.eq(labels_expanded).any(dim=1)\n",
    "\n",
    "            eval_total += labels.size(0)\n",
    "            eval_correct_top3 += correct_top3.sum().item()\n",
    "            prof.step()\n",
    "\n",
    "    # End timing\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.synchronize()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate evaluation time\n",
    "    eval_time = end_time - start_time\n",
    "\n",
    "    eval_loss /= len(test_loader)\n",
    "    eval_accuracy_top1 = eval_correct_top1 / eval_total\n",
    "    eval_accuracy_top3 = eval_correct_top3 / eval_total\n",
    "\n",
    "    print(f\"Eval Loss: {eval_loss:.4f}\")\n",
    "    print(f\"Eval Top-1 Accuracy: {eval_accuracy_top1:.4f}\")\n",
    "    print(f\"Eval Top-3 Accuracy: {eval_accuracy_top3:.4f}\")\n",
    "    print(f\"Evaluation Time: {eval_time:.2f} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l51ddNJD-6mG"
   },
   "outputs": [],
   "source": [
    "# Function to count parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())# if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0_qbcpNEFyM",
    "outputId": "e3110e3a-ea25-4ed9-b479-6f0847a12895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85875556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:28<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.8210\n",
      "Eval Top-1 Accuracy: 0.7794\n",
      "Eval Top-3 Accuracy: 0.9228\n",
      "Evaluation Time: 208.27 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Profile evaluation for models with torch profiling\n",
    "\n",
    "print(count_parameters(model))\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    eval_op(model, prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 11.13 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = prof.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         3.22%      66.993ms       100.00%        2.082s     346.947ms       6.96 Kb      -5.98 Gb             6  \n",
      "                                           aten::linear         0.43%       9.031ms        57.08%        1.188s       2.713ms       2.92 Gb           0 b           438  \n",
      "                                            aten::addmm        39.14%     814.859ms        56.16%        1.169s       2.669ms       2.92 Gb       2.92 Gb           438  \n",
      "                     aten::scaled_dot_product_attention         0.05%     960.781us        17.10%     356.039ms       4.945ms     332.44 Mb      -5.19 Mb            72  \n",
      "      aten::_scaled_dot_product_flash_attention_for_cpu        16.77%     348.998ms        17.06%     355.079ms       4.932ms     337.63 Mb    -110.95 Mb            72  \n",
      "                                            aten::copy_        16.85%     350.805ms        16.85%     350.805ms     779.567us           0 b           0 b           450  \n",
      "                                              aten::add         6.36%     132.483ms         6.36%     132.483ms     883.221us     692.58 Mb     692.58 Mb           150  \n",
      "                                       aten::layer_norm         0.07%       1.536ms         6.08%     126.521ms     843.474us     692.58 Mb      -1.80 Mb           150  \n",
      "                                aten::native_layer_norm         5.82%     121.186ms         6.00%     124.985ms     833.232us     694.38 Mb           0 b           150  \n",
      "                                           aten::conv2d         0.00%      70.991us         5.93%     123.446ms      20.574ms      27.56 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.082s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm        39.14%     814.859ms        56.16%        1.169s       2.669ms       2.92 Gb       2.92 Gb           438  \n",
      "                                             aten::gelu         2.24%      46.625ms         2.24%      46.625ms     647.570us       1.30 Gb       1.30 Gb            72  \n",
      "                                            aten::empty         0.31%       6.397ms         0.31%       6.397ms       8.394us       1.14 Gb       1.14 Gb           762  \n",
      "                                              aten::add         6.36%     132.483ms         6.36%     132.483ms     883.221us     692.58 Mb     692.58 Mb           150  \n",
      "                                              aten::cat         1.18%      24.538ms         1.19%      24.755ms       4.126ms      27.70 Mb      27.70 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.45%       9.455ms         0.46%       9.599ms       1.600ms      27.56 Mb      27.56 Mb             6  \n",
      "                                     aten::_log_softmax         0.01%     118.212us         0.01%     118.212us      19.702us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.01%     152.412us         0.01%     152.412us      25.402us       1.69 Kb       1.69 Kb             6  \n",
      "                                    aten::empty_strided         0.00%      45.147us         0.00%      45.147us       3.762us         768 b         768 b            12  \n",
      "                                              aten::max         0.01%     181.885us         0.02%     320.266us      53.378us         576 b         576 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.082s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3rE3hv15Lt8",
    "outputId": "de5d4d30-bca2-4677-8c41-7d0376c58403",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load student model as deit-tiny\n",
    "\n",
    "teacher_model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=100)\n",
    "teacher_model.to(device)\n",
    "\n",
    "state_dict = torch.load('vit_cifar100_finetuned.pth', weights_only=True, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the state dict into your model\n",
    "teacher_model.load_state_dict(state_dict)\n",
    "student_model = ViTForImageClassification.from_pretrained(\"facebook/deit-tiny-patch16-224\")\n",
    "student_model.classifier = torch.nn.Linear(student_model.classifier.in_features, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2-9e-ii75-6"
   },
   "outputs": [],
   "source": [
    "# Only train student model\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Set models to evaluation mode\n",
    "teacher_model.eval()\n",
    "student_model.train()\n",
    "\n",
    "# Load feature extractor\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-75M95Dz7-QX"
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(student_model.parameters(), lr=1e-4)\n",
    "\n",
    "# Distillation parameters\n",
    "temperature = 2.0\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMNWtghH8CFD"
   },
   "outputs": [],
   "source": [
    "# Define distillation loss for student training - combination of cross entropy and KL diverence between teacher and student\n",
    "def distillation_loss(student_logits, teacher_logits, labels, temperature=2.0, alpha=0.5):\n",
    "    hard_loss = F.cross_entropy(student_logits, labels)\n",
    "    soft_loss = F.kl_div(\n",
    "        F.log_softmax(student_logits / temperature, dim=1),\n",
    "        F.softmax(teacher_logits / temperature, dim=1),\n",
    "        reduction='batchmean'\n",
    "    ) * (temperature ** 2)\n",
    "    return alpha * hard_loss + (1 - alpha) * soft_loss\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    eval_total = 0\n",
    "    eval_correct_top1 = 0\n",
    "    eval_correct_top3 = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Top-1 Accuracy\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            eval_correct_top1 += (predicted == labels).sum().item()\n",
    "\n",
    "            # Top-3 Accuracy\n",
    "            _, top3_predicted = outputs.logits.topk(3, 1, largest=True, sorted=True)\n",
    "            labels_expanded = labels.view(-1, 1).expand_as(top3_predicted)\n",
    "            correct = top3_predicted.eq(labels_expanded).any(dim=1)\n",
    "            eval_correct_top3 += correct.sum().item()\n",
    "\n",
    "            eval_total += labels.size(0)\n",
    "\n",
    "    accuracy_top1 = eval_correct_top1 / eval_total\n",
    "    accuracy_top3 = eval_correct_top3 / eval_total\n",
    "\n",
    "    return accuracy_top1, accuracy_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mefS83Jy8ItF",
    "outputId": "8bdb8d7e-685e-4dd2-df07-65d7108d5f31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 3125/3125 [12:56<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Loss: 1.9217, Test Accuracy Top-1: 0.7226, Top-3: 0.9002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4: 100%|██████████| 3125/3125 [12:56<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4, Loss: 0.9378, Test Accuracy Top-1: 0.7553, Top-3: 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4: 100%|██████████| 3125/3125 [12:55<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4, Loss: 0.6997, Test Accuracy Top-1: 0.7682, Top-3: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4: 100%|██████████| 3125/3125 [12:57<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4, Loss: 0.5574, Test Accuracy Top-1: 0.7785, Top-3: 0.9256\n"
     ]
    }
   ],
   "source": [
    "# Student train loop\n",
    "num_epochs = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "teacher_model.to(device)\n",
    "student_model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    student_model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Get teacher predictions\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(images)\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "\n",
    "        # Get student predictions\n",
    "        student_outputs = student_model(images)\n",
    "        student_logits = student_outputs.logits\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate test accuracy\n",
    "    test_accuracy_top1, test_accuracy_top3 = evaluate(student_model, test_loader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "          f\"Test Accuracy Top-1: {test_accuracy_top1:.4f}, Top-3: {test_accuracy_top3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVRhIZdQK_1P"
   },
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), 'distilled_deit_tiny.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2JbjiujRjCV",
    "outputId": "5cd2b150-dc93-4989-a46c-9b69f729a15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5543716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [01:17<00:00, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.7914\n",
      "Eval Top-1 Accuracy: 0.7785\n",
      "Eval Top-3 Accuracy: 0.9256\n",
      "Evaluation Time: 77.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Profile student\n",
    "print(count_parameters(student_model))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as stud_prof:\n",
    "    eval_op(student_model, stud_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 2.87 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = stud_prof.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         6.46%      44.926ms       100.00%     694.978ms     115.830ms      -9.18 Mb      -1.51 Gb             6  \n",
      "                                           aten::linear         0.63%       4.387ms        36.48%     253.516ms     578.803us     748.00 Mb           0 b           438  \n",
      "                                            aten::addmm         9.54%      66.330ms        35.00%     243.219ms     555.293us     748.00 Mb     748.00 Mb           438  \n",
      "                                            aten::copy_        25.16%     174.858ms        25.16%     174.858ms     388.574us           0 b           0 b           450  \n",
      "                                             aten::gelu        13.67%      95.001ms        13.67%      95.001ms       1.319ms     332.44 Mb     332.44 Mb            72  \n",
      "                     aten::scaled_dot_product_attention         0.11%     774.450us        12.24%      85.073ms       1.182ms      83.11 Mb      -1.30 Mb            72  \n",
      "      aten::_scaled_dot_product_flash_attention_for_cpu        11.46%      79.658ms        12.13%      84.299ms       1.171ms      84.41 Mb    -110.95 Mb            72  \n",
      "                                           aten::conv2d         0.01%      35.659us        10.95%      76.119ms      12.687ms       6.89 Mb           0 b             6  \n",
      "                                      aten::convolution         0.01%      88.146us        10.95%      76.083ms      12.681ms       6.89 Mb           0 b             6  \n",
      "                                     aten::_convolution         0.01%      92.477us        10.93%      75.995ms      12.666ms       6.89 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 694.978ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm         9.54%      66.330ms        35.00%     243.219ms     555.293us     748.00 Mb     748.00 Mb           438  \n",
      "                                            aten::empty         0.98%       6.788ms         0.98%       6.788ms       8.955us     377.20 Mb     377.20 Mb           758  \n",
      "                                             aten::gelu        13.67%      95.001ms        13.67%      95.001ms       1.319ms     332.44 Mb     332.44 Mb            72  \n",
      "                                              aten::add         7.36%      51.143ms         7.36%      51.143ms     340.953us     173.14 Mb     173.14 Mb           150  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         1.33%       9.263ms         1.35%       9.352ms       1.559ms      18.38 Mb      18.38 Mb             6  \n",
      "                                              aten::cat         2.32%      16.142ms         2.37%      16.459ms       2.743ms       6.93 Mb       6.93 Mb             6  \n",
      "                                     aten::_log_softmax         0.02%     105.565us         0.02%     105.565us      17.594us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.02%     163.047us         0.02%     163.047us      27.175us       1.69 Kb       1.69 Kb             6  \n",
      "                                    aten::empty_strided         0.00%      30.877us         0.00%      30.877us       2.573us         768 b         768 b            12  \n",
      "                                              aten::max         0.02%     127.023us         0.03%     219.363us      36.560us         576 b         576 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 694.978ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stud_prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(stud_prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rD-NNazui1f",
    "outputId": "5e81148e-1d54-4a18-b5ce-e6ae5d5bd32c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained ViT model\n",
    "model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=100)\n",
    "model.to(device)\n",
    "\n",
    "state_dict = torch.load('vit_cifar100_finetuned.pth', weights_only=True, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the state dict into your model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "## Train model below before running this\n",
    "\n",
    "student_model = ViTForImageClassification.from_pretrained(\"facebook/deit-tiny-patch16-224\")\n",
    "student_model.classifier = torch.nn.Linear(student_model.classifier.in_features, 100)\n",
    "student_model.to(device)\n",
    "\n",
    "state_dict = torch.load('distilled_deit_tiny.pth', weights_only=True, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load the state dict into your model\n",
    "student_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cr0vkn08bdqU",
    "outputId": "ab389e0c-0cd2-4d26-b213-87e8cbdb0b40"
   },
   "outputs": [],
   "source": [
    "# Function for pruning attention heads with redefinition of forward function\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch_pruning as tp\n",
    "from transformers.models.vit.modeling_vit import ViTSelfAttention\n",
    "import math\n",
    "import copy\n",
    "\n",
    "def prune_vit_model(original_model, device=\"cpu\", pruning_ratio=0.1, iterative_steps=5):\n",
    "    model = copy.deepcopy(original_model)\n",
    "    \n",
    "    def new_forward(self, hidden_states, head_mask=None, output_attentions=False):\n",
    "        batch_size, seq_length, _ = hidden_states.shape\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = self.key(hidden_states)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "        return outputs\n",
    "\n",
    "    model.eval().to(device)\n",
    "    example_inputs = torch.randn(1, 3, 224, 224).to(device)\n",
    "    num_heads = {}\n",
    "    ignored_layers = [model.classifier]\n",
    "\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, ViTSelfAttention):\n",
    "            m.forward = new_forward.__get__(m, ViTSelfAttention)\n",
    "            num_heads[m.query] = m.num_attention_heads\n",
    "\n",
    "    imp = tp.importance.GroupNormImportance(2)\n",
    "    pruner = tp.pruner.MetaPruner(\n",
    "        model,\n",
    "        example_inputs,\n",
    "        iterative_steps=iterative_steps,\n",
    "        global_pruning=False,\n",
    "        importance=imp,\n",
    "        ignored_layers=ignored_layers,\n",
    "        num_heads=num_heads,\n",
    "        prune_head_dims=False,\n",
    "        prune_num_heads=True,\n",
    "        head_pruning_ratio=pruning_ratio,\n",
    "        round_to=2,\n",
    "    )\n",
    "\n",
    "    for i, g in enumerate(pruner.step(interactive=True)):\n",
    "        g.prune()\n",
    "\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, ViTSelfAttention):\n",
    "            m.num_attention_heads = pruner.num_heads[m.query]\n",
    "            m.attention_head_size = m.query.out_features // m.num_attention_heads\n",
    "            m.all_head_size = m.num_attention_heads * m.attention_head_size\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NX0i-PZuzjVX",
    "outputId": "163086eb-14e7-441b-e86f-fcc13886bcbc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ap8235/HPML/Project/torch_pruning/dependency.py:699: UserWarning: Unwrapped parameters detected: ['vit.embeddings.cls_token', 'vit.embeddings.position_embeddings'].\n",
      " Torch-Pruning will prune the last non-singleton dimension of these parameters. If you wish to change this behavior, please provide an unwrapped_parameters argument.\n",
      "  warnings.warn(warning_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75856508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [04:11<00:00,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.9397\n",
      "Eval Top-1 Accuracy: 0.7445\n",
      "Eval Top-3 Accuracy: 0.8975\n",
      "Evaluation Time: 251.68 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# step 7\n",
    "model7 = prune_vit_model(model, device=\"cpu\", pruning_ratio=0.1, iterative_steps=7)\n",
    "print(count_parameters(model7))\n",
    "\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof7:\n",
    "    eval_op(model7, prof7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 20.28 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = prof7.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         2.10%      80.397ms       100.00%        3.823s     637.193ms      -9.18 Mb      -8.97 Gb             6  \n",
      "                                            aten::copy_        42.89%        1.640s        42.89%        1.640s       2.024ms           0 b           0 b           810  \n",
      "                                           aten::linear         0.17%       6.351ms        39.46%        1.509s       3.444ms       2.78 Gb           0 b           438  \n",
      "                                            aten::addmm        17.46%     667.335ms        39.09%        1.494s       3.412ms       2.78 Gb       2.78 Gb           438  \n",
      "                                           aten::matmul         0.08%       3.021ms        24.07%     920.137ms       6.390ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                            aten::clone         0.04%       1.684ms        21.45%     820.108ms       2.848ms       1.30 Gb           0 b           288  \n",
      "                                             aten::gelu        18.05%     690.083ms        18.05%     690.083ms       9.584ms       1.21 Gb       1.21 Gb            72  \n",
      "                                          aten::reshape         0.08%       2.975ms        15.26%     583.472ms     810.378us     997.31 Mb           0 b           720  \n",
      "                                              aten::bmm         8.71%     333.155ms         8.72%     333.218ms       2.314ms       1.32 Gb       1.32 Gb           144  \n",
      "                                       aten::contiguous         0.00%     179.804us         6.32%     241.773ms       3.358ms     332.44 Mb           0 b            72  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.823s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm        17.46%     667.335ms        39.09%        1.494s       3.412ms       2.78 Gb       2.78 Gb           438  \n",
      "                                            aten::empty         0.19%       7.292ms         0.19%       7.292ms       9.620us       1.95 Gb       1.95 Gb           758  \n",
      "                                              aten::bmm         8.71%     333.155ms         8.72%     333.218ms       2.314ms       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu        18.05%     690.083ms        18.05%     690.083ms       9.584ms       1.21 Gb       1.21 Gb            72  \n",
      "                                         aten::_softmax         0.89%      33.913ms         0.89%      33.913ms     471.016us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         0.95%      36.228ms         0.98%      37.623ms     522.548us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         1.77%      67.670ms         1.77%      67.670ms     451.136us     642.08 Mb     642.08 Mb           150  \n",
      "                                              aten::cat         0.64%      24.593ms         0.65%      24.683ms       4.114ms      25.68 Mb      25.68 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.17%       6.557ms         0.17%       6.633ms       1.105ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%      80.330us         0.00%      80.330us      13.388us      18.75 Kb      18.75 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.823s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof7.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(prof7.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmdjDfJrfQ9V",
    "outputId": "1fd0cc98-87f3-402c-d622-6d8967fc36f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74396196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:31<00:00,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.9919\n",
      "Eval Top-1 Accuracy: 0.7346\n",
      "Eval Top-3 Accuracy: 0.8910\n",
      "Evaluation Time: 211.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# step 6\n",
    "model6 = prune_vit_model(model, device=\"cpu\", pruning_ratio=0.1, iterative_steps=6)\n",
    "print(count_parameters(model6))\n",
    "\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof6:\n",
    "    eval_op(model6, prof6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 20.19 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = prof6.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         2.39%      78.950ms       100.00%        3.309s     551.536ms      -9.18 Mb      -8.91 Gb             6  \n",
      "                                           aten::linear         0.18%       6.003ms        52.64%        1.742s       3.977ms       2.76 Gb           0 b           438  \n",
      "                                            aten::addmm        19.21%     635.692ms        52.22%        1.728s       3.945ms       2.76 Gb       2.76 Gb           438  \n",
      "                                            aten::copy_        38.32%        1.268s        38.32%        1.268s       1.565ms           0 b           0 b           810  \n",
      "                                             aten::gelu        26.72%     884.264ms        26.72%     884.264ms      12.281ms       1.19 Gb       1.19 Gb            72  \n",
      "                                           aten::matmul         0.08%       2.660ms         8.27%     273.756ms       1.901ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                            aten::clone         0.04%       1.464ms         5.50%     182.001ms     631.947us       1.30 Gb           0 b           288  \n",
      "                                          aten::reshape         0.08%       2.800ms         4.32%     142.841ms     198.390us     997.31 Mb           0 b           720  \n",
      "                                              aten::bmm         3.87%     128.008ms         3.87%     128.066ms     889.345us       1.32 Gb       1.32 Gb           144  \n",
      "                                           aten::conv2d         0.00%      42.453us         3.04%     100.648ms      16.775ms      25.27 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.309s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm        19.21%     635.692ms        52.22%        1.728s       3.945ms       2.76 Gb       2.76 Gb           438  \n",
      "                                            aten::empty         0.20%       6.605ms         0.20%       6.605ms       8.713us       1.95 Gb       1.95 Gb           758  \n",
      "                                              aten::bmm         3.87%     128.008ms         3.87%     128.066ms     889.345us       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu        26.72%     884.264ms        26.72%     884.264ms      12.281ms       1.19 Gb       1.19 Gb            72  \n",
      "                                         aten::_softmax         1.08%      35.745ms         1.08%      35.745ms     496.465us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         0.81%      26.923ms         0.86%      28.345ms     393.685us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         1.24%      41.198ms         1.24%      41.198ms     274.654us     634.86 Mb     634.86 Mb           150  \n",
      "                                              aten::cat         0.75%      24.724ms         0.75%      24.806ms       4.134ms      25.39 Mb      25.39 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.20%       6.707ms         0.20%       6.780ms       1.130ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%      90.873us         0.00%      90.873us      15.145us      18.75 Kb      18.75 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.309s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof6.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(prof6.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auuSszf31vBL",
    "outputId": "5ae4383c-b6f6-4554-9f14-bf56a7d031f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72056206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [04:12<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.1247\n",
      "Eval Top-1 Accuracy: 0.7015\n",
      "Eval Top-3 Accuracy: 0.8695\n",
      "Evaluation Time: 252.65 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "model5 = prune_vit_model(model, device=\"cpu\", pruning_ratio=0.1, iterative_steps=5)\n",
    "print(count_parameters(model5))\n",
    "\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof5:\n",
    "    eval_op(model5, prof5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 20.05 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = prof5.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         2.87%      75.774ms       100.00%        2.640s     440.029ms      -9.18 Mb      -8.83 Gb             6  \n",
      "                                           aten::linear         0.23%       6.073ms        54.25%        1.432s       3.270ms       2.73 Gb           0 b           438  \n",
      "                                            aten::addmm        22.62%     597.320ms        53.72%        1.418s       3.238ms       2.73 Gb       2.73 Gb           438  \n",
      "                                            aten::copy_        34.58%     912.934ms        34.58%     912.934ms       1.127ms           0 b           0 b           810  \n",
      "                                             aten::gelu        23.04%     608.279ms        23.04%     608.279ms       8.448ms       1.17 Gb       1.17 Gb            72  \n",
      "                                           aten::matmul         0.09%       2.389ms         7.00%     184.935ms       1.284ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                           aten::conv2d         0.00%      50.102us         4.87%     128.561ms      21.427ms      24.76 Mb           0 b             6  \n",
      "                                      aten::convolution         0.00%      67.728us         4.87%     128.511ms      21.419ms      24.76 Mb           0 b             6  \n",
      "                                     aten::_convolution         0.00%      73.346us         4.86%     128.443ms      21.407ms      24.76 Mb           0 b             6  \n",
      "                               aten::mkldnn_convolution         4.86%     128.216ms         4.86%     128.370ms      21.395ms      24.76 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.640s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm        22.62%     597.320ms        53.72%        1.418s       3.238ms       2.73 Gb       2.73 Gb           438  \n",
      "                                            aten::empty         0.25%       6.713ms         0.25%       6.713ms       8.856us       1.93 Gb       1.93 Gb           758  \n",
      "                                              aten::bmm         3.62%      95.610ms         3.62%      95.665ms     664.340us       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu        23.04%     608.279ms        23.04%     608.279ms       8.448ms       1.17 Gb       1.17 Gb            72  \n",
      "                                         aten::_softmax         0.52%      13.710ms         0.52%      13.710ms     190.422us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         0.64%      16.880ms         0.69%      18.313ms     254.349us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         2.54%      67.130ms         2.54%      67.130ms     447.536us     622.24 Mb     622.24 Mb           150  \n",
      "                                              aten::cat         1.25%      32.929ms         1.25%      33.059ms       5.510ms      24.89 Mb      24.89 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.25%       6.575ms         0.25%       6.643ms       1.107ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%      99.638us         0.00%      99.638us      16.606us      18.75 Kb      18.75 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.640s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof5.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(prof5.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMt8ErUj2Nqk",
    "outputId": "28ce3d7a-1cd7-4a30-a9d6-38bfd8099b6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68951428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:57<00:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.2572\n",
      "Eval Top-1 Accuracy: 0.6726\n",
      "Eval Top-3 Accuracy: 0.8476\n",
      "Evaluation Time: 237.79 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "model4 = prune_vit_model(model, device=\"cpu\", pruning_ratio=0.1, iterative_steps=4)\n",
    "print(count_parameters(model4))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof4:\n",
    "    eval_op(model4, prof4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 19.86 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = prof4.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         3.06%      72.869ms       100.00%        2.382s     396.966ms      -4.59 Mb      -8.72 Gb             6  \n",
      "                                           aten::linear         0.29%       6.888ms        49.13%        1.170s       2.672ms       2.68 Gb           0 b           438  \n",
      "                                            aten::addmm        25.59%     609.464ms        48.50%        1.155s       2.637ms       2.68 Gb       2.68 Gb           438  \n",
      "                                            aten::copy_        34.45%     820.563ms        34.45%     820.563ms       1.013ms           0 b           0 b           810  \n",
      "                                             aten::gelu        16.73%     398.416ms        16.73%     398.416ms       5.534ms       1.14 Gb       1.14 Gb            72  \n",
      "                                           aten::matmul         0.11%       2.641ms        15.78%     375.847ms       2.610ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                            aten::clone         0.07%       1.586ms        11.84%     281.981ms     979.099us       1.30 Gb           0 b           288  \n",
      "                                          aten::reshape         0.13%       2.990ms        10.60%     252.377ms     350.524us     997.31 Mb           0 b           720  \n",
      "                                              aten::bmm         5.08%     121.004ms         5.08%     121.073ms     840.782us       1.32 Gb       1.32 Gb           144  \n",
      "                                           aten::conv2d         0.00%      50.196us         4.17%      99.276ms      16.546ms      24.12 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.382s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm        25.59%     609.464ms        48.50%        1.155s       2.637ms       2.68 Gb       2.68 Gb           438  \n",
      "                                            aten::empty         0.31%       7.475ms         0.31%       7.475ms       9.836us       1.92 Gb       1.92 Gb           760  \n",
      "                                              aten::bmm         5.08%     121.004ms         5.08%     121.073ms     840.782us       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu        16.73%     398.416ms        16.73%     398.416ms       5.534ms       1.14 Gb       1.14 Gb            72  \n",
      "                                         aten::_softmax         1.27%      30.256ms         1.27%      30.256ms     420.218us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         1.40%      33.337ms         1.46%      34.759ms     482.759us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         2.69%      64.132ms         2.69%      64.132ms     427.548us     606.01 Mb     606.01 Mb           150  \n",
      "                                              aten::cat         0.88%      21.005ms         0.90%      21.376ms       3.563ms      24.24 Mb      24.24 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.42%      10.008ms         0.42%      10.116ms       1.686ms      22.97 Mb      22.97 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%      81.606us         0.00%      81.606us      13.601us      18.75 Kb      18.75 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.382s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof4.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(prof4.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63703268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:43<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.7575\n",
      "Eval Top-1 Accuracy: 0.5660\n",
      "Eval Top-3 Accuracy: 0.7551\n",
      "Evaluation Time: 223.65 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "model3 = prune_vit_model(model, device=\"cpu\", pruning_ratio=0.1, iterative_steps=3)\n",
    "print(count_parameters(model3))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof3:\n",
    "    eval_op(model3, prof3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 19.52 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = prof3.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         3.69%      84.549ms       100.00%        2.290s     381.619ms      -9.18 Mb      -8.53 Gb             6  \n",
      "                                           aten::linear         0.28%       6.423ms        49.95%        1.144s       2.611ms       2.60 Gb           0 b           438  \n",
      "                                            aten::addmm        25.50%     583.974ms        49.26%        1.128s       2.575ms       2.60 Gb       2.60 Gb           438  \n",
      "                                            aten::copy_        32.55%     745.358ms        32.55%     745.358ms     920.196us           0 b           0 b           810  \n",
      "                                             aten::gelu        20.54%     470.378ms        20.54%     470.378ms       6.533ms       1.08 Gb       1.08 Gb            72  \n",
      "                                           aten::matmul         0.12%       2.682ms        12.52%     286.769ms       1.991ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                            aten::clone         0.06%       1.454ms         9.16%     209.702ms     728.131us       1.30 Gb           0 b           288  \n",
      "                                          aten::reshape         0.14%       3.103ms         8.00%     183.063ms     254.254us     997.31 Mb           0 b           720  \n",
      "                                           aten::conv2d         0.00%      54.441us         4.60%     105.219ms      17.536ms      22.97 Mb           0 b             6  \n",
      "                                      aten::convolution         0.00%      76.514us         4.59%     105.164ms      17.527ms      22.97 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.290s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::addmm        25.50%     583.974ms        49.26%        1.128s       2.575ms       2.60 Gb       2.60 Gb           438  \n",
      "                                            aten::empty         0.40%       9.074ms         0.40%       9.074ms      11.971us       1.89 Gb       1.89 Gb           758  \n",
      "                                              aten::bmm         4.40%     100.725ms         4.40%     100.787ms     699.910us       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu        20.54%     470.378ms        20.54%     470.378ms       6.533ms       1.08 Gb       1.08 Gb            72  \n",
      "                                         aten::_softmax         1.62%      37.032ms         1.62%      37.032ms     514.335us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         1.31%      30.017ms         1.38%      31.499ms     437.484us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         1.39%      31.875ms         1.39%      31.875ms     212.500us     577.15 Mb     577.15 Mb           150  \n",
      "                                              aten::cat         0.73%      16.666ms         0.74%      16.842ms       2.807ms      23.09 Mb      23.09 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.29%       6.713ms         0.30%       6.793ms       1.132ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%     111.392us         0.00%     111.392us      18.565us      18.75 Kb      18.75 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.290s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof3.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(prof3.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to quantize a model. Only works on CPU\n",
    "\n",
    "def quantize(model):\n",
    "    model = model.to('cpu')\n",
    "    # Perform dynamic quantization\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        model,\n",
    "            {torch.nn.Linear}, \n",
    "        dtype=torch.qint8\n",
    "    )\n",
    "    \n",
    "    # To use the quantized model\n",
    "    quantized_model.to('cpu')\n",
    "    quantized_model.eval()\n",
    "\n",
    "    return quantized_model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:21<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.8766\n",
      "Eval Top-1 Accuracy: 0.7673\n",
      "Eval Top-3 Accuracy: 0.9150\n",
      "Evaluation Time: 201.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Profile quantized model\n",
    "quant_model = quantize(model)\n",
    "\n",
    "print(count_parameters(quant_model))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as quant_prof:\n",
    "    eval_op(quant_model, quant_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 16.96 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = quant_prof.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         8.80%     102.920ms       100.00%        1.169s     194.848ms      -9.18 Mb      -5.98 Gb             6  \n",
      "                              quantized::linear_dynamic        62.47%     730.347ms        63.64%     743.987ms       1.699ms       2.92 Gb      -2.92 Gb           438  \n",
      "                                           aten::conv2d         0.01%      60.649us         8.55%      99.906ms      16.651ms      27.56 Mb           0 b             6  \n",
      "                                      aten::convolution         0.01%      75.419us         8.54%      99.846ms      16.641ms      27.56 Mb           0 b             6  \n",
      "                                     aten::_convolution         0.01%     104.175us         8.53%      99.770ms      16.628ms      27.56 Mb           0 b             6  \n",
      "                               aten::mkldnn_convolution         8.51%      99.529ms         8.53%      99.666ms      16.611ms      27.56 Mb           0 b             6  \n",
      "                     aten::scaled_dot_product_attention         0.06%     752.674us         7.14%      83.493ms       1.160ms     332.44 Mb      -5.19 Mb            72  \n",
      "      aten::_scaled_dot_product_flash_attention_for_cpu         6.82%      79.731ms         7.08%      82.741ms       1.149ms     337.63 Mb    -110.95 Mb            72  \n",
      "                                             aten::gelu         4.05%      47.337ms         4.05%      47.337ms     657.462us       1.30 Gb       1.30 Gb            72  \n",
      "                                              aten::add         3.21%      37.569ms         3.21%      37.569ms     250.459us     692.58 Mb     692.58 Mb           150  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.169s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         1.34%      15.649ms         1.34%      15.649ms       9.542us       6.99 Gb       6.99 Gb          1640  \n",
      "                                             aten::gelu         4.05%      47.337ms         4.05%      47.337ms     657.462us       1.30 Gb       1.30 Gb            72  \n",
      "                                              aten::add         3.21%      37.569ms         3.21%      37.569ms     250.459us     692.58 Mb     692.58 Mb           150  \n",
      "                                              aten::cat         2.12%      24.842ms         2.13%      24.925ms       4.154ms      27.70 Mb      27.70 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.58%       6.777ms         0.59%       6.846ms       1.141ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.01%      75.366us         0.01%      75.366us      12.561us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.01%     116.293us         0.01%     116.293us      19.382us       1.69 Kb       1.69 Kb             6  \n",
      "                                    aten::empty_strided         0.00%      29.765us         0.00%      29.765us       2.480us         768 b         768 b            12  \n",
      "                                              aten::max         0.01%     141.944us         0.02%     229.143us      38.190us         576 b         576 b             6  \n",
      "                                               aten::eq         0.01%      77.230us         0.01%      77.230us       6.436us         192 b         192 b            12  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.169s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(quant_prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(quant_prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quant_model.state_dict(), \"vit_cifar100_finetuned_quantized.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:51<00:00,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.9723\n",
      "Eval Top-1 Accuracy: 0.7360\n",
      "Eval Top-3 Accuracy: 0.8918\n",
      "Evaluation Time: 231.27 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "quant_model7 = quantize(model7)\n",
    "\n",
    "print(count_parameters(quant_model7))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as quant_prof7:\n",
    "    eval_op(quant_model7, quant_prof7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 25.84 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = quant_prof7.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         7.03%     124.294ms       100.00%        1.768s     294.584ms      -9.18 Mb      -8.97 Gb             6  \n",
      "                              quantized::linear_dynamic        54.96%     971.465ms        55.66%     983.735ms       2.246ms       2.78 Gb      -2.78 Gb           438  \n",
      "                                           aten::matmul         0.20%       3.577ms        12.51%     221.178ms       1.536ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                             aten::gelu        10.69%     188.865ms        10.69%     188.865ms       2.623ms       1.21 Gb       1.21 Gb            72  \n",
      "                                            aten::clone         0.12%       2.076ms         8.28%     146.332ms     497.728us       1.30 Gb           0 b           294  \n",
      "                                            aten::copy_         7.93%     140.183ms         7.93%     140.183ms     370.854us           0 b           0 b           378  \n",
      "                                          aten::reshape         0.13%       2.295ms         7.02%     124.078ms     430.827us     997.31 Mb           0 b           288  \n",
      "                                           aten::conv2d         0.00%      56.733us         5.32%      94.109ms      15.685ms      25.55 Mb           0 b             6  \n",
      "                                      aten::convolution         0.00%      77.558us         5.32%      94.052ms      15.675ms      25.55 Mb           0 b             6  \n",
      "                                     aten::_convolution         0.01%     163.222us         5.32%      93.975ms      15.662ms      25.55 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.768s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         0.98%      17.410ms         0.98%      17.410ms      10.616us       7.52 Gb       7.52 Gb          1640  \n",
      "                                              aten::bmm         5.12%      90.419ms         5.12%      90.503ms     628.492us       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu        10.69%     188.865ms        10.69%     188.865ms       2.623ms       1.21 Gb       1.21 Gb            72  \n",
      "                                         aten::_softmax         0.79%      13.939ms         0.79%      13.939ms     193.594us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         0.88%      15.527ms         0.98%      17.333ms     240.734us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         1.71%      30.296ms         1.71%      30.296ms     201.970us     642.08 Mb     642.08 Mb           150  \n",
      "                                              aten::cat         0.72%      12.743ms         0.74%      13.018ms       2.170ms      25.68 Mb      25.68 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.43%       7.560ms         0.43%       7.653ms       1.276ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%      71.016us         0.00%      71.016us      11.836us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.01%     124.227us         0.01%     124.227us      20.704us       1.69 Kb       1.69 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.768s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(quant_prof7.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(quant_prof7.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:34<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.0220\n",
      "Eval Top-1 Accuracy: 0.7261\n",
      "Eval Top-3 Accuracy: 0.8869\n",
      "Evaluation Time: 214.25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "quant_model6 = quantize(model6)\n",
    "\n",
    "print(count_parameters(quant_model6))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as quant_prof6:\n",
    "    eval_op(quant_model6, quant_prof6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 25.71 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = quant_prof6.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         6.08%     147.129ms       100.00%        2.421s     403.491ms      -9.18 Mb      -8.91 Gb             6  \n",
      "                              quantized::linear_dynamic        56.84%        1.376s        57.49%        1.392s       3.178ms       2.76 Gb      -2.76 Gb           438  \n",
      "                                       aten::layer_norm         0.05%       1.187ms         9.34%     226.143ms       1.508ms     634.86 Mb      -1.80 Mb           150  \n",
      "                                aten::native_layer_norm         8.99%     217.737ms         9.29%     224.956ms       1.500ms     636.67 Mb           0 b           150  \n",
      "                                             aten::gelu         8.45%     204.574ms         8.45%     204.574ms       2.841ms       1.19 Gb       1.19 Gb            72  \n",
      "                                           aten::matmul         0.13%       3.112ms         7.59%     183.662ms       1.275ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                            aten::clone         0.09%       2.103ms         4.19%     101.322ms     344.631us       1.30 Gb           0 b           294  \n",
      "                                            aten::copy_         3.99%      96.476ms         3.99%      96.476ms     255.228us           0 b           0 b           378  \n",
      "                                          aten::reshape         0.09%       2.212ms         3.81%      92.130ms     319.896us     997.31 Mb           0 b           288  \n",
      "                                           aten::conv2d         0.00%      43.074us         3.77%      91.300ms      15.217ms      25.27 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.421s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         0.92%      22.159ms         0.92%      22.159ms      13.512us       7.46 Gb       7.46 Gb          1640  \n",
      "                                              aten::bmm         3.54%      85.583ms         3.54%      85.678ms     594.987us       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu         8.45%     204.574ms         8.45%     204.574ms       2.841ms       1.19 Gb       1.19 Gb            72  \n",
      "                                         aten::_softmax         1.49%      36.002ms         1.49%      36.002ms     500.026us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         1.19%      28.782ms         1.26%      30.504ms     423.669us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         3.05%      73.908ms         3.05%      73.908ms     492.718us     634.86 Mb     634.86 Mb           150  \n",
      "                                              aten::cat         0.46%      11.030ms         0.46%      11.115ms       1.852ms      25.39 Mb      25.39 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.26%       6.413ms         0.27%       6.487ms       1.081ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%      79.196us         0.00%      79.196us      13.199us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.01%     125.903us         0.01%     125.903us      20.984us       1.69 Kb       1.69 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.421s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(quant_prof6.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(quant_prof6.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:32<00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.1457\n",
      "Eval Top-1 Accuracy: 0.6997\n",
      "Eval Top-3 Accuracy: 0.8662\n",
      "Evaluation Time: 212.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "quant_model5 = quantize(model5)\n",
    "\n",
    "print(count_parameters(quant_model5))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as quant_prof5:\n",
    "    eval_op(quant_model5, quant_prof5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 25.50 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = quant_prof5.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         8.82%     131.045ms       100.00%        1.486s     247.698ms      -9.18 Mb      -8.83 Gb             6  \n",
      "                              quantized::linear_dynamic        42.89%     637.411ms        43.63%     648.407ms       1.480ms       2.73 Gb      -2.73 Gb           438  \n",
      "                                           aten::matmul         0.27%       3.987ms        21.43%     318.448ms       2.211ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                            aten::clone         0.17%       2.468ms        12.81%     190.406ms     647.640us       1.30 Gb           0 b           294  \n",
      "                                            aten::copy_        12.42%     184.637ms        12.42%     184.637ms     488.458us           0 b           0 b           378  \n",
      "                                          aten::reshape         0.16%       2.385ms        11.13%     165.370ms     574.201us     997.31 Mb           0 b           288  \n",
      "                                              aten::bmm         9.83%     146.083ms         9.84%     146.178ms       1.015ms       1.32 Gb       1.32 Gb           144  \n",
      "                                           aten::conv2d         0.00%      64.198us         5.64%      83.844ms      13.974ms      24.76 Mb           0 b             6  \n",
      "                                      aten::convolution         0.01%      89.977us         5.64%      83.780ms      13.963ms      24.76 Mb           0 b             6  \n",
      "                                     aten::_convolution         0.01%     125.726us         5.63%      83.690ms      13.948ms      24.76 Mb           0 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.486s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         1.01%      14.958ms         1.01%      14.958ms       9.121us       7.38 Gb       7.38 Gb          1640  \n",
      "                                              aten::bmm         9.83%     146.083ms         9.84%     146.178ms       1.015ms       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu         2.34%      34.837ms         2.34%      34.837ms     483.845us       1.17 Gb       1.17 Gb            72  \n",
      "                                         aten::_softmax         2.65%      39.441ms         2.65%      39.441ms     547.791us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         2.82%      41.880ms         2.94%      43.732ms     607.388us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         4.20%      62.469ms         4.20%      62.469ms     416.457us     622.24 Mb     622.24 Mb           150  \n",
      "                                              aten::cat         1.08%      15.996ms         1.09%      16.199ms       2.700ms      24.89 Mb      24.89 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.41%       6.040ms         0.41%       6.114ms       1.019ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%      73.345us         0.00%      73.345us      12.224us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.01%     147.315us         0.01%     147.315us      24.553us       1.69 Kb       1.69 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.486s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(quant_prof5.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(quant_prof5.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:30<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.2551\n",
      "Eval Top-1 Accuracy: 0.6718\n",
      "Eval Top-3 Accuracy: 0.8477\n",
      "Evaluation Time: 210.57 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "quant_model4 = quantize(model4)\n",
    "\n",
    "print(count_parameters(quant_model4))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as quant_prof4:\n",
    "    eval_op(quant_model4, quant_prof4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 25.21 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = quant_prof4.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         3.40%     156.946ms       100.00%        4.619s     769.886ms      -9.18 Mb      -8.72 Gb             6  \n",
      "                              quantized::linear_dynamic        42.46%        1.961s        42.84%        1.979s       4.518ms       2.68 Gb      -2.68 Gb           438  \n",
      "                                             aten::gelu        14.86%     686.491ms        14.86%     686.491ms       9.535ms       1.14 Gb       1.14 Gb            72  \n",
      "                                           aten::matmul         0.09%       4.079ms        14.33%     661.782ms       4.596ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                              aten::bmm        10.51%     485.413ms        10.51%     485.539ms       3.372ms       1.32 Gb       1.32 Gb           144  \n",
      "                                            aten::clone         0.05%       2.369ms         7.98%     368.754ms       1.254ms       1.30 Gb           0 b           294  \n",
      "                                            aten::copy_         7.83%     361.787ms         7.83%     361.787ms     957.109us           0 b           0 b           378  \n",
      "                                       aten::contiguous         0.00%     174.774us         4.41%     203.738ms       2.612ms     332.56 Mb           0 b            78  \n",
      "                                              aten::div         4.25%     196.130ms         4.28%     197.935ms       2.749ms    1023.28 Mb    1023.28 Mb            72  \n",
      "                                       aten::layer_norm         0.03%       1.318ms         4.26%     196.817ms       1.312ms     606.01 Mb      -1.80 Mb           150  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.619s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         0.53%      24.567ms         0.53%      24.567ms      14.980us       7.27 Gb       7.27 Gb          1640  \n",
      "                                              aten::bmm        10.51%     485.413ms        10.51%     485.539ms       3.372ms       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu        14.86%     686.491ms        14.86%     686.491ms       9.535ms       1.14 Gb       1.14 Gb            72  \n",
      "                                         aten::_softmax         3.99%     184.405ms         3.99%     184.405ms       2.561ms    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         4.25%     196.130ms         4.28%     197.935ms       2.749ms    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         4.09%     188.853ms         4.09%     188.853ms       1.259ms     606.01 Mb     606.01 Mb           150  \n",
      "                                              aten::cat         0.62%      28.697ms         0.62%      28.860ms       4.810ms      24.24 Mb      24.24 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.17%       7.907ms         0.17%       7.981ms       1.330ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.00%      91.680us         0.00%      91.680us      15.280us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.00%     128.496us         0.00%     128.496us      21.416us       1.69 Kb       1.69 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.619s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(quant_prof4.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(quant_prof4.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [03:18<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 1.7058\n",
      "Eval Top-1 Accuracy: 0.5770\n",
      "Eval Top-3 Accuracy: 0.7673\n",
      "Evaluation Time: 198.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "quant_model3 = quantize(model3)\n",
    "\n",
    "print(count_parameters(quant_model3))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as quant_prof3:\n",
    "    eval_op(quant_model3, quant_prof3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 24.71 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = quant_prof3.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*         8.34%     132.023ms       100.00%        1.584s     263.992ms      -9.18 Mb      -8.53 Gb             6  \n",
      "                              quantized::linear_dynamic        52.09%     825.087ms        52.72%     835.018ms       1.906ms       2.60 Gb      -2.60 Gb           438  \n",
      "                                           aten::matmul         0.21%       3.353ms        15.63%     247.607ms       1.719ms       1.32 Gb    -997.31 Mb           144  \n",
      "                                            aten::clone         0.12%       1.908ms        15.25%     241.536ms     821.550us       1.30 Gb           0 b           294  \n",
      "                                            aten::copy_        14.89%     235.865ms        14.89%     235.865ms     623.982us           0 b           0 b           378  \n",
      "                                          aten::reshape         0.14%       2.289ms         9.63%     152.463ms     529.387us     997.31 Mb           0 b           288  \n",
      "                                       aten::layer_norm         0.08%       1.234ms         5.86%      92.770ms     618.469us     577.15 Mb      -1.80 Mb           150  \n",
      "                                       aten::contiguous         0.01%     165.563us         5.82%      92.245ms       1.183ms     332.55 Mb           0 b            78  \n",
      "                                aten::native_layer_norm         5.37%      85.064ms         5.78%      91.537ms     610.243us     578.95 Mb           0 b           150  \n",
      "                                              aten::bmm         5.61%      88.824ms         5.61%      88.919ms     617.490us       1.32 Gb       1.32 Gb           144  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.584s\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         1.05%      16.624ms         1.05%      16.624ms      10.136us       7.08 Gb       7.08 Gb          1640  \n",
      "                                              aten::bmm         5.61%      88.824ms         5.61%      88.919ms     617.490us       1.32 Gb       1.32 Gb           144  \n",
      "                                             aten::gelu         0.98%      15.472ms         0.98%      15.472ms     214.893us       1.08 Gb       1.08 Gb            72  \n",
      "                                         aten::_softmax         1.40%      22.247ms         1.40%      22.247ms     308.992us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::div         1.57%      24.822ms         1.68%      26.575ms     369.092us    1023.28 Mb    1023.28 Mb            72  \n",
      "                                              aten::add         2.35%      37.256ms         2.35%      37.256ms     248.374us     577.15 Mb     577.15 Mb           150  \n",
      "                                              aten::cat         0.04%     602.813us         0.06%     878.559us     146.427us      23.09 Mb      23.09 Mb             6  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         0.45%       7.108ms         0.45%       7.182ms       1.197ms      18.38 Mb      18.38 Mb             6  \n",
      "                                     aten::_log_softmax         0.01%     100.100us         0.01%     100.100us      16.683us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.01%     106.791us         0.01%     106.791us      17.798us       1.69 Kb       1.69 Kb             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.584s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(quant_prof3.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(quant_prof3.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1250/1250 [01:36<00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.7968\n",
      "Eval Top-1 Accuracy: 0.7792\n",
      "Eval Top-3 Accuracy: 0.9251\n",
      "Evaluation Time: 96.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "quant_stud_model = quantize(student_model)\n",
    "\n",
    "print(count_parameters(quant_stud_model))\n",
    "\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(\n",
    "        wait=1,\n",
    "        warmup=1,\n",
    "        active=3,\n",
    "        repeat=2),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as quant_stud_prof:\n",
    "    eval_op(quant_stud_model, quant_stud_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU Memory Usage: 4.33 GB\n"
     ]
    }
   ],
   "source": [
    "key_averages = quant_stud_prof.key_averages()\n",
    "total_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "print(f\"Total CPU Memory Usage: {total_memory / (1024 * 1024*1024):.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ProfilerStep*        22.22%      91.765ms       100.00%     412.956ms      68.826ms      -9.18 Mb      -1.51 Gb             6  \n",
      "                              quantized::linear_dynamic        28.21%     116.509ms        29.74%     122.824ms     280.419us     748.00 Mb    -748.04 Mb           438  \n",
      "                                           aten::conv2d         0.02%      89.950us        21.58%      89.108ms      14.851ms       6.89 Mb           0 b             6  \n",
      "                                      aten::convolution         0.03%     106.851us        21.56%      89.018ms      14.836ms       6.89 Mb           0 b             6  \n",
      "                                     aten::_convolution         0.02%     100.978us        21.53%      88.911ms      14.818ms       6.89 Mb           0 b             6  \n",
      "                               aten::mkldnn_convolution        21.48%      88.686ms        21.51%      88.810ms      14.802ms       6.89 Mb           0 b             6  \n",
      "                     aten::scaled_dot_product_attention         0.16%     648.482us        13.45%      55.542ms     771.423us      83.11 Mb      -1.30 Mb            72  \n",
      "      aten::_scaled_dot_product_flash_attention_for_cpu        12.41%      51.260ms        13.29%      54.894ms     762.416us      84.41 Mb    -110.95 Mb            72  \n",
      "                                       aten::layer_norm         0.19%     801.319us         2.79%      11.520ms      76.801us     173.14 Mb      -1.80 Mb           150  \n",
      "                                              aten::add         2.75%      11.362ms         2.75%      11.362ms      75.750us     173.14 Mb     173.14 Mb           150  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 412.956ms\n",
      "\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         2.37%       9.767ms         2.37%       9.767ms       5.955us       1.83 Gb       1.83 Gb          1640  \n",
      "                                             aten::gelu         2.09%       8.620ms         2.09%       8.620ms     119.722us     332.44 Mb     332.44 Mb            72  \n",
      "                                              aten::add         2.75%      11.362ms         2.75%      11.362ms      75.750us     173.14 Mb     173.14 Mb           150  \n",
      "enumerate(DataLoader)#_MultiProcessingDataLoaderIter...         1.81%       7.458ms         1.82%       7.530ms       1.255ms      18.38 Mb      18.38 Mb             6  \n",
      "                                              aten::cat         2.08%       8.583ms         2.19%       9.057ms       1.509ms       6.93 Mb       6.93 Mb             6  \n",
      "                                       aten::empty_like         0.48%       1.989ms         0.89%       3.658ms       8.238us     748.04 Mb       1.15 Mb           444  \n",
      "                                     aten::_log_softmax         0.02%      77.651us         0.02%      77.651us      12.942us      18.75 Kb      18.75 Kb             6  \n",
      "                                             aten::topk         0.06%     240.723us         0.06%     240.723us      40.121us       1.69 Kb       1.69 Kb             6  \n",
      "                                    aten::empty_strided         0.01%      59.118us         0.01%      59.118us       4.927us         768 b         768 b            12  \n",
      "                                              aten::max         0.05%     189.809us         0.07%     283.120us      47.187us         576 b         576 b             6  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 412.956ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(quant_stud_prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "print(quant_stud_prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "# Evaluation function calculating accuracy, latency and CPU memory\n",
    "def evaluate_model(model, test_loader=test_loader):\n",
    "    model.eval()\n",
    "    correct_top3 = 0\n",
    "    total = 0\n",
    "    latency = 0\n",
    "    gpu_memory = 0\n",
    "    cpu_memory = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with profile(\n",
    "        activities=[ProfilerActivity.CPU],\n",
    "        schedule=torch.profiler.schedule(\n",
    "            wait=1,\n",
    "            warmup=1,\n",
    "            active=3,\n",
    "            repeat=2),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=False\n",
    "    ) as prof:\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                prof.step()\n",
    "                \n",
    "                outputs = model(inputs).logits\n",
    "                \n",
    "                # Top-3 accuracy\n",
    "                _, predicted_top3 = outputs.topk(3, 1, largest=True, sorted=True)\n",
    "                correct_top3 += sum([1 for i, label in enumerate(labels) if label in predicted_top3[i]])\n",
    "                \n",
    "                total += labels.size(0)\n",
    "\n",
    "    end_time = time.time()\n",
    "    latency = end_time - start_time\n",
    "\n",
    "    # Measure GPU memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory = torch.cuda.max_memory_allocated()\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset peak memory stats for next run\n",
    "    \n",
    "    key_averages = prof.key_averages()\n",
    "    cpu_memory = sum(avg.cpu_memory_usage for avg in key_averages)\n",
    "\n",
    "    accuracy_top3 = 100 * correct_top3 / total\n",
    "\n",
    "    return accuracy_top3, latency, cpu_memory / (1024 * 1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "import numpy as np\n",
    "search_space = {\n",
    "    'original': {\n",
    "        'quantization': [True, False],\n",
    "        'pruning_steps': [3, 4, 5, 6, 7, 8]\n",
    "    },\n",
    "    'student': {\n",
    "        'quantization': [True, False],\n",
    "        'pruning_steps': [15, 16, 17, 18, 19, 20]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define random search strategy based on given inputs\n",
    "def random_search(original_model, student_model, test_loader, num_iterations=10, max_params=np.inf, max_mem = np.inf):\n",
    "    best_config = None\n",
    "    best_score = float('-inf')\n",
    "    student_params = count_parameters(student_model)\n",
    "    tried_configs = set()\n",
    "\n",
    "    model_type = 'original' if max_params > student_params else 'student'\n",
    "    config_space = search_space[model_type]\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Generate a new configuration\n",
    "        while True:\n",
    "            config = {\n",
    "                'model_type': model_type,\n",
    "                'quantization': np.random.choice(config_space['quantization']),\n",
    "                'pruning_steps': np.random.choice(config_space['pruning_steps'])\n",
    "            }\n",
    "            config_tuple = tuple(config.items())\n",
    "            if config_tuple not in tried_configs:\n",
    "                tried_configs.add(config_tuple)\n",
    "                break\n",
    "\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        print(f\"Config: {config}\")\n",
    "\n",
    "        # Select and copy the appropriate model\n",
    "        model = copy.deepcopy(original_model if config['model_type'] == 'original' else student_model)\n",
    "\n",
    "        # Apply pruning\n",
    "        model = prune_vit_model(model, iterative_steps=config['pruning_steps'])\n",
    "\n",
    "        # Apply quantization if specified\n",
    "        if config['quantization']:\n",
    "            model = quantize(model)\n",
    "\n",
    "        # Check if the model meets the parameter constraint\n",
    "        if count_parameters(model) > max_params:\n",
    "            print(\"Failed: Exceeds parameter limit\")\n",
    "            continue\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy, latency, memory = evaluate_model(model, test_loader)\n",
    "        # Check if the model meets the memory constraint\n",
    "        if(memory > max_mem):\n",
    "            print(\"Failed: Exceeds memory limit\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Accuracy: {accuracy:.2f}%, Latency: {latency:.4f}s, Memory: {memory:.2f}GB\")\n",
    "\n",
    "        # Calculate a combined score\n",
    "        score = accuracy - 0.1 * latency - memory\n",
    "        print(f\"Score: {score:.4f}\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_config = config\n",
    "\n",
    "    return best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(best_config, original_model, student_model):\n",
    "    if best_config['model_type'] == 'original':\n",
    "        final_model = copy.deepcopy(original_model)\n",
    "    else:\n",
    "        final_model = copy.deepcopy(student_model)\n",
    "\n",
    "    final_model = prune_vit_model(final_model, iterative_steps = best_config['pruning_steps'])\n",
    "\n",
    "    if best_config['quantization']:\n",
    "        final_model = quantize(final_model)\n",
    "    \n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Config: {'model_type': 'original', 'quantization': np.False_, 'pruning_steps': np.int64(3)}\n",
      "Accuracy: 75.51%, Latency: 210.2708s, Memory: 19.52GB\n",
      "Score: 34.9646\n",
      "Iteration 2:\n",
      "Config: {'model_type': 'original', 'quantization': np.True_, 'pruning_steps': np.int64(4)}\n",
      "Accuracy: 84.77%, Latency: 227.0053s, Memory: 25.21GB\n",
      "Score: 36.8581\n",
      "Iteration 3:\n",
      "Config: {'model_type': 'original', 'quantization': np.False_, 'pruning_steps': np.int64(7)}\n",
      "Failed: Exceeds parameter limit\n",
      "Iteration 4:\n",
      "Config: {'model_type': 'original', 'quantization': np.True_, 'pruning_steps': np.int64(6)}\n",
      "Accuracy: 88.69%, Latency: 216.6466s, Memory: 25.71GB\n",
      "Score: 41.3157\n",
      "Iteration 5:\n",
      "Config: {'model_type': 'original', 'quantization': np.True_, 'pruning_steps': np.int64(5)}\n",
      "Accuracy: 86.62%, Latency: 213.7290s, Memory: 25.50GB\n",
      "Score: 39.7510\n",
      "Iteration 6:\n",
      "Config: {'model_type': 'original', 'quantization': np.False_, 'pruning_steps': np.int64(8)}\n",
      "Failed: Exceeds parameter limit\n",
      "Iteration 7:\n",
      "Config: {'model_type': 'original', 'quantization': np.True_, 'pruning_steps': np.int64(7)}\n",
      "Accuracy: 89.18%, Latency: 234.9038s, Memory: 25.84GB\n",
      "Score: 39.8470\n",
      "Iteration 8:\n",
      "Config: {'model_type': 'original', 'quantization': np.False_, 'pruning_steps': np.int64(5)}\n",
      "Failed: Exceeds parameter limit\n",
      "Iteration 9:\n",
      "Config: {'model_type': 'original', 'quantization': np.False_, 'pruning_steps': np.int64(6)}\n",
      "Failed: Exceeds parameter limit\n",
      "Iteration 10:\n",
      "Config: {'model_type': 'original', 'quantization': np.True_, 'pruning_steps': np.int64(8)}\n",
      "Accuracy: 89.52%, Latency: 225.4354s, Memory: 25.96GB\n",
      "Score: 41.0177\n"
     ]
    }
   ],
   "source": [
    "best_config = random_search(model, student_model, test_loader, num_iterations=10, max_params=70000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'original',\n",
       " 'quantization': np.True_,\n",
       " 'pruning_steps': np.int64(6)}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88.69, 200.24301671981812, 25.70965152978897)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_model = best_model(best_config, model, student_model)\n",
    "evaluate_model(optimized_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "Config: {'model_type': 'student', 'quantization': np.True_, 'pruning_steps': np.int64(19)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/ap8235/HPML/Project/torch_pruning/dependency.py:699: UserWarning: Unwrapped parameters detected: ['vit.embeddings.cls_token', 'vit.embeddings.position_embeddings'].\n",
      " Torch-Pruning will prune the last non-singleton dimension of these parameters. If you wish to change this behavior, please provide an unwrapped_parameters argument.\n",
      "  warnings.warn(warning_str)\n",
      "[W1211 16:22:12.335792552 CPUAllocator.cpp:249] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.24%, Latency: 115.1802s, Memory: 6.61GB\n",
      "Score: 60.1162\n",
      "Iteration 2:\n",
      "Config: {'model_type': 'student', 'quantization': np.True_, 'pruning_steps': np.int64(15)}\n",
      "Accuracy: 73.00%, Latency: 115.8008s, Memory: 6.59GB\n",
      "Score: 54.8279\n",
      "Iteration 3:\n",
      "Config: {'model_type': 'student', 'quantization': np.False_, 'pruning_steps': np.int64(17)}\n",
      "Accuracy: 78.39%, Latency: 94.9493s, Memory: 5.18GB\n",
      "Score: 63.7152\n",
      "Iteration 4:\n",
      "Config: {'model_type': 'student', 'quantization': np.False_, 'pruning_steps': np.int64(15)}\n",
      "Accuracy: 73.57%, Latency: 85.4092s, Memory: 5.17GB\n",
      "Score: 59.8626\n",
      "Iteration 5:\n",
      "Config: {'model_type': 'student', 'quantization': np.False_, 'pruning_steps': np.int64(20)}\n",
      "Accuracy: 78.37%, Latency: 92.3090s, Memory: 5.17GB\n",
      "Score: 63.9721\n",
      "Iteration 6:\n",
      "Config: {'model_type': 'student', 'quantization': np.True_, 'pruning_steps': np.int64(18)}\n",
      "Accuracy: 78.24%, Latency: 114.6155s, Memory: 6.61GB\n",
      "Score: 60.1637\n",
      "Iteration 7:\n",
      "Config: {'model_type': 'student', 'quantization': np.False_, 'pruning_steps': np.int64(18)}\n",
      "Accuracy: 78.44%, Latency: 86.3182s, Memory: 5.18GB\n",
      "Score: 64.6258\n",
      "Iteration 8:\n",
      "Config: {'model_type': 'student', 'quantization': np.False_, 'pruning_steps': np.int64(19)}\n",
      "Accuracy: 78.44%, Latency: 79.8348s, Memory: 5.18GB\n",
      "Score: 65.2741\n",
      "Iteration 9:\n",
      "Config: {'model_type': 'student', 'quantization': np.True_, 'pruning_steps': np.int64(17)}\n",
      "Accuracy: 78.37%, Latency: 119.2109s, Memory: 6.61GB\n",
      "Score: 59.8384\n",
      "Iteration 10:\n",
      "Config: {'model_type': 'student', 'quantization': np.True_, 'pruning_steps': np.int64(16)}\n",
      "Accuracy: 78.37%, Latency: 118.4363s, Memory: 6.61GB\n",
      "Score: 59.9159\n"
     ]
    }
   ],
   "source": [
    "best_config = random_search(model, student_model, test_loader, num_iterations=10, max_params=5300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_type': 'student',\n",
       " 'quantization': np.False_,\n",
       " 'pruning_steps': np.int64(19)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.44, 89.92148685455322, 5.164437800645828)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_model = best_model(best_config, model, student_model)\n",
    "evaluate_model(optimized_model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "hpml",
   "language": "python",
   "name": "hpml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
